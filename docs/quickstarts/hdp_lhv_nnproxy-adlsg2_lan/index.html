<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><title>Hortonworks (HDP) with Live Hive &amp; NN Proxy to ADLS Gen2 with Live Analytics · WANdisco docs</title><meta name="viewport" content="width=device-width"/><meta name="generator" content="Docusaurus"/><meta name="description" content="_THIS GUIDE IS WORK IN PROGRESS, PLEASE DO NOT FOLLOW ANYTHING HERE UNTIL THIS WARNING IS REMOVED_"/><meta name="docsearch:language" content="en"/><meta property="og:title" content="Hortonworks (HDP) with Live Hive &amp; NN Proxy to ADLS Gen2 with Live Analytics · WANdisco docs"/><meta property="og:type" content="website"/><meta property="og:url" content="https://wandisco.github.io/wandisco-documentation/ https://wandisco.github.io/wandisco-documentation/"/><meta property="og:description" content="_THIS GUIDE IS WORK IN PROGRESS, PLEASE DO NOT FOLLOW ANYTHING HERE UNTIL THIS WARNING IS REMOVED_"/><meta property="og:image" content="https://wandisco.github.io/wandisco-documentation/ https://wandisco.github.io/wandisco-documentation/img/undraw_online.svg"/><meta name="twitter:card" content="summary"/><meta name="twitter:image" content="https://wandisco.github.io/wandisco-documentation/ https://wandisco.github.io/wandisco-documentation/img/undraw_tweetstorm.svg"/><link rel="shortcut icon" href="https://wandisco.github.io/wandisco-documentation/img/favicon.png"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/docsearch.js/1/docsearch.min.css"/><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css"/><script type="text/javascript" src="https://buttons.github.io/buttons.js"></script><script src="https://wandisco.github.io/wandisco-documentation/js/scrollSpy.js"></script><link rel="stylesheet" href="https://wandisco.github.io/wandisco-documentation/css/main.css"/><script src="https://wandisco.github.io/wandisco-documentation/js/codetabs.js"></script></head><body class="sideNavVisible separateOnPageNav"><div class="fixedHeaderContainer"><div class="headerWrapper wrapper"><header><a href="https://wandisco.github.io/wandisco-documentation/"><img class="logo" src="https://wandisco.github.io/wandisco-documentation/img/favicon.png" alt="WANdisco docs"/><h2 class="headerTitleWithLogo">WANdisco docs</h2></a><div class="navigationWrapper navigationSlider"><nav class="slidingNav"><ul class="nav-site nav-site-internal"><li class=""><a href="https://wandisco.github.io/wandisco-documentation/docs/quickstarts/quickstart-config" target="_self">Quickstarts</a></li><li class=""><a href="https://wandisco.github.io/wandisco-documentation/docs/docs/doc1" target="_self">Docs</a></li><li class=""><a href="https://wandisco.github.io/wandisco-documentation/docs/glossary/a" target="_self">Glossary</a></li><li class=""><a href="https://wandisco.github.io/wandisco-documentation/docs/api/api" target="_self">API</a></li><li class=""><a href="https://wandisco.github.io/wandisco-documentation/help" target="_self">Help</a></li><li class="navSearchWrapper reactNavSearchWrapper"><input type="text" id="search_input_react" placeholder="Search" title="Search"/></li></ul></nav></div></header></div></div><div class="navPusher"><div class="docMainWrapper wrapper"><div class="container mainContainer"><div class="wrapper"><div class="post"><header class="postHeader"><h1 class="postHeaderTitle">Hortonworks (HDP) with Live Hive &amp; NN Proxy to ADLS Gen2 with Live Analytics</h1></header><article><div><span><p><em>THIS GUIDE IS WORK IN PROGRESS, PLEASE DO NOT FOLLOW ANYTHING HERE UNTIL THIS WARNING IS REMOVED</em></p>
<p>Use this quickstart if you want to configure Fusion to connect to Hortonworks (HDP) and ADLS Gen2 storage/Databricks cluster. This guide will also include Live Hive on the HDP cluster, and Live Analytics on the ADLS Gen2/Databricks cluster.</p>
<p>Please see the <a href="https://wandisco.github.io/wandisco-documentation/docs/troubleshooting/useful_info">Useful information</a> section for additional commands and help.</p>
<h2><a class="anchor" aria-hidden="true" id="prerequisites"></a><a href="#prerequisites" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Prerequisites</h2>
<ul>
<li><p>Azure VM instance set up and running, with root access available (instructions were tested on RHEL 7.7).</p>
<p>(TBC) Minimum size VM recommendation = <strong>Standard A4m v2 (4 vcpus, 32 GiB memory).</strong></p></li>
<li><p><a href="https://docs.docker.com/install/">Docker</a> (v19.03.3 or higher), <a href="https://docs.docker.com/compose/install/">Docker Compose</a> (v1.24.1 or higher), and <a href="https://git-scm.com/book/en/v2/Getting-Started-Installing-Git">Git</a> installed on instance.</p></li>
<li><p>Administrator credentials for the HDP Ambari Manager and root access via terminal.</p></li>
<li><p>Network connectivity to the Ambari Manager and NameNode.</p></li>
<li><p>Credentials for accessing the Data Lake Storage Gen2 and Databricks cluster.</p></li>
<li><p>Network connectivity to the Data Lake Storage Gen2 and Databricks cluster.</p></li>
</ul>
<h2><a class="anchor" aria-hidden="true" id="guidance"></a><a href="#guidance" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Guidance</h2>
<h3><a class="anchor" aria-hidden="true" id="initial-setup"></a><a href="#initial-setup" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Initial Setup</h3>
<ol>
<li><p>Clone the Fusion docker repository to your Azure VM instance:</p>
<p><code>git clone -b features/livehive-merge https://github.com/WANdisco/fusion-docker-compose.git</code></p></li>
<li><p>Change to the repository directory:</p>
<p><code>cd fusion-docker-compose</code></p></li>
<li><p>Edit the Common configuration file for the purposes of this demo:</p>
<p><code>vi common.conf</code></p>
<p>Change:</p>
<pre><code class="hljs css language-json"># save versions
save_var FUSION_BASE_VERSION           "2.14.2.1" "$SAVE_ENV"
save_var FUSION_IMAGE_RELEASE          "3594"     "$SAVE_ENV"
save_var FUSION_NN_PROXY_VERSION       "4.0.0.6"  "$SAVE_ENV"
save_var FUSION_NN_PROXY_IMAGE_RELEASE "3594"     "$SAVE_ENV"
save_var FUSION_ONEUI_VERSION          "1.0.0"    "$SAVE_ENV"
save_var FUSION_LIVEHIVE_VERSION       "5.0.0.0"  "$SAVE_ENV"
</code></pre>
<p>To:</p>
<pre><code class="hljs css language-json"># save versions
save_var FUSION_BASE_VERSION           "2.14.2.1" "$SAVE_ENV"
save_var FUSION_IMAGE_RELEASE          "3600"     "$SAVE_ENV"
save_var FUSION_NN_PROXY_VERSION       "4.0.0.6"  "$SAVE_ENV"
save_var FUSION_NN_PROXY_IMAGE_RELEASE "3600"     "$SAVE_ENV"
save_var FUSION_ONEUI_VERSION          "1.0.0"    "$SAVE_ENV"
save_var FUSION_LIVEHIVE_VERSION       "5.0.0.1"  "$SAVE_ENV"
</code></pre>
<p>Once complete, save and quit the file (e.g. <code>:wq!</code>).</p></li>
<li><p>Run the setup script:</p>
<p><code>./setup-env.sh</code></p></li>
<li><p>Follow the prompts to configure your zones, see the next section below for guidance on this.</p></li>
</ol>
<h3><a class="anchor" aria-hidden="true" id="setup-prompts"></a><a href="#setup-prompts" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Setup prompts</h3>
<p><em>Zone type</em></p>
<ul>
<li>For the purposes of this quickstart, please enter <code>hdp</code> for the first zone type, and <code>adls2</code> for the second zone type.</li>
</ul>
<p><em>Zone name</em></p>
<ul>
<li>If defining a zone name, please note that each zone must have a different name (i.e. they cannot match). Otherwise, press enter to leave as default.</li>
</ul>
<p><em>Licenses</em></p>
<ul>
<li>Trial licenses will last 30 days and are limited to 1TB of replicated data. Press enter to leave as default trial license.</li>
</ul>
<p><em>Docker hostname</em></p>
<ul>
<li>For the purposes of this quickstart, this can be changed to the IP address of your docker host.</li>
</ul>
<p><em>Example entries for HDP</em></p>
<ul>
<li><p>HDP version: <code>2.6.5</code></p></li>
<li><p>Hadoop NameNode IP/hostname: <code>namenode.example.com</code> - The value will be the hostname defined in the <code>fs.defaultFS</code> property in the HDFS config, but not including the <code>hdfs://</code> prefix.</p></li>
<li><p>NameNode port: <code>8020</code> - The value will be the port defined in the <code>fs.defaultFS</code> property in the HDFS config.</p></li>
<li><p>NameNode Service Name: <code>&lt;docker_hostname/IP&gt;:8890</code> - Press enter to leave as default.</p></li>
</ul>
<p><em>Example entries for Live Hive</em></p>
<ul>
<li><p>Enter <code>livehive</code> for the HDP zone when prompted to select a plugin.</p></li>
<li><p>Hive Metastore hostname: <code>metastore.hostname.com</code> - The HDP cluster's Hive Metastore hostname, can be seen by hovering over the Hive Metastore in the Hive summary page.</p></li>
<li><p>Hive Metastore port: <code>9083</code> - This value can be left as default.</p></li>
</ul>
<p><em>Example entries for ADLS Gen2</em></p>
<ul>
<li><p>HDI version: <code>3.6</code></p></li>
<li><p>Storage account: <code>adlsg2storage</code></p></li>
<li><p>Storage container: <code>fusionreplication</code></p></li>
<li><p>Account key: <code>KEY_1_STRING</code> - the Primary Access Key is now referred to as &quot;Key1&quot; in Microsoft’s documentation. You can get the Access Key from the Microsoft Azure storage account under the <strong>Access Keys</strong> section.</p></li>
<li><p>default FS: <code>abfss://fusionreplication@adlsg2storage.dfs.core.windows.net/</code> - press enter for the default value.</p></li>
<li><p>underlying FS: <code>abfs://fusionreplication@adlsg2storage.dfs.core.windows.net/</code> - press enter for the default value.</p></li>
<li><p>Enter <code>NONE</code> for the adls2 zone when prompted to select a plugin.</p></li>
</ul>
<h3><a class="anchor" aria-hidden="true" id="startup"></a><a href="#startup" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Startup</h3>
<p>After all the prompts have been completed, you will be able to start the containers.</p>
<ol>
<li><p>Perform a docker image pull of specific images to be used for this quickstart:</p>
<pre><code class="hljs">docker image pull registry.wandisco.com:<span class="hljs-number">8423</span>/wandisco/fusion-ui-server-hcfs-azure-hdi<span class="hljs-number">-3.6</span>:<span class="hljs-number">2.14</span><span class="hljs-number">.2</span><span class="hljs-number">.1</span><span class="hljs-number">-3594</span>
docker image tag registry.wandisco.com:<span class="hljs-number">8423</span>/wandisco/fusion-ui-server-hcfs-azure-hdi<span class="hljs-number">-3.6</span>:<span class="hljs-number">2.14</span><span class="hljs-number">.2</span><span class="hljs-number">.1</span><span class="hljs-number">-3594</span> wandisco/fusion-ui-server-hcfs-azure-hdi<span class="hljs-number">-3.6</span>:<span class="hljs-number">2.14</span><span class="hljs-number">.2</span><span class="hljs-number">.1</span><span class="hljs-number">-3600</span>
docker image pull registry.wandisco.com:<span class="hljs-number">8423</span>/wandisco/fusion-server-hcfs-azure-hdi<span class="hljs-number">-3.6</span>:<span class="hljs-number">2.14</span><span class="hljs-number">.2</span><span class="hljs-number">.1</span><span class="hljs-number">-3594</span>
docker image tag registry.wandisco.com:<span class="hljs-number">8423</span>/wandisco/fusion-server-hcfs-azure-hdi<span class="hljs-number">-3.6</span>:<span class="hljs-number">2.14</span><span class="hljs-number">.2</span><span class="hljs-number">.1</span><span class="hljs-number">-3594</span> wandisco/fusion-server-hcfs-azure-hdi<span class="hljs-number">-3.6</span>:<span class="hljs-number">2.14</span><span class="hljs-number">.2</span><span class="hljs-number">.1</span><span class="hljs-number">-3600</span>
docker image pull registry.wandisco.com:<span class="hljs-number">8423</span>/wandisco/fusion-ihc-server-hcfs-azure-hdi<span class="hljs-number">-3.6</span>:<span class="hljs-number">2.14</span><span class="hljs-number">.2</span><span class="hljs-number">.1</span><span class="hljs-number">-3594</span>
docker image tag registry.wandisco.com:<span class="hljs-number">8423</span>/wandisco/fusion-ihc-server-hcfs-azure-hdi<span class="hljs-number">-3.6</span>:<span class="hljs-number">2.14</span><span class="hljs-number">.2</span><span class="hljs-number">.1</span><span class="hljs-number">-3594</span> wandisco/fusion-ihc-server-hcfs-azure-hdi<span class="hljs-number">-3.6</span>:<span class="hljs-number">2.14</span><span class="hljs-number">.2</span><span class="hljs-number">.1</span><span class="hljs-number">-3600</span>
</code></pre></li>
<li><p>Ensure that Docker is started:</p>
<p><code>systemctl status docker</code></p>
<p>If not, start the Docker service:</p>
<p><code>systemctl start docker</code></p></li>
<li><p>Start the Fusion containers with:</p>
<p><code>docker-compose up -d</code></p></li>
<li><p>If the Induction container comes up before all other containers, please run the previous command again to ensure the zones are inducted together.</p>
<p><code>docker-compose up -d</code></p></li>
</ol>
<h3><a class="anchor" aria-hidden="true" id="live-hive-config-changes"></a><a href="#live-hive-config-changes" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Live Hive config changes</h3>
<ol>
<li><p>Log into one of the containers for the HDP zone.</p>
<p>You will first need to obtain the name of a suitable container, this can be done by running the command below.</p>
<p><code>docker-compose ps</code> <em>- obtain list of container names.</em></p>
<p>Utilise a container name from the HDP zone in the command below, for example, <code>fusion-docker-compose_fusion-ui-server-hdp_1</code>.</p>
<p><code>docker exec -u root -it fusion-docker-compose_fusion-ui-server-hdp_1 bash</code></p></li>
<li><p>Symlink the Live Hive config files to the Fusion Server config path:</p>
<p><code>ln -s /etc/wandisco/fusion/plugins/hive/* /etc/wandisco/fusion/server/</code></p></li>
<li><p>Edit the UI properties file and adjust the following properties:</p>
<p><code>vi /opt/wandisco/fusion-ui-server/properties/ui.properties</code></p>
<p>Change:</p>
<pre><code class="hljs css language-json">user.username=
user.password=
manager.type=AMBARI
</code></pre>
<p>To:</p>
<pre><code class="hljs css language-json">user.username=admin
user.password=$2a$10$jQH1VJ/zBByUD8d0prf0A.Uh9FDKuW/AWUUEayefsP/owiIuFrRAW
manager.type=UNMANAGED_BIGINSIGHTS
</code></pre>
<p>Once complete, save and quit the file (e.g. <code>:wq!</code>).</p></li>
<li><p>Add an additional property to the Live Hive config:</p>
<p><code>vi /etc/wandisco/fusion/plugins/hive/live-hive-site.xml</code></p>
<p>Add the following property and value below:</p>
<pre><code class="hljs css language-json">  &lt;property&gt;
    &lt;name&gt;live.hive.cluster.delegation.token.delayed.removal.interval.in.seconds&lt;/name&gt;
    &lt;value&gt;5&lt;/value&gt;
  &lt;/property&gt;
</code></pre>
<p>Once complete, save and quit the file (e.g. <code>:wq!</code>).</p></li>
<li><p>Exit back into the docker host and restart the docker containers so that the configuration changes are picked up.</p>
<p><code>exit</code></p>
<p><code>docker-compose restart</code></p></li>
<li><p>Log into the Fusion UI for the HDP zone, and activate the Live Hive plugin.</p>
<p><code>http://&lt;docker_hostname/IP&gt;:8083</code></p>
<p>Username: <code>admin</code>
Password: <code>wandisco</code></p>
<p>Proceed to the Settings tab and select the <em>Live Hive: Plugin Activation</em> option on the left-hand panel.</p>
<p>Click on the <em>Activate</em> option.</p></li>
</ol>
<h3><a class="anchor" aria-hidden="true" id="activate-namenode-proxy-and-live-hive-proxy-on-the-hdp-cluster"></a><a href="#activate-namenode-proxy-and-live-hive-proxy-on-the-hdp-cluster" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Activate NameNode Proxy and Live Hive Proxy on the HDP cluster</h3>
<ol>
<li><p>Log into the Ambari UI for the HDP cluster.</p></li>
<li><p>Adjust a property in the HDFS config so that it references the NameNode Proxy.</p>
<p><strong>HDFS -&gt; Configs -&gt; Filter for <code>fs.defaultFS</code></strong></p>
<p>Adjust the value of <code>fs.defaultFS</code> to:</p>
<pre><code class="hljs css language-json">hdfs://&lt;docker_IP_address&gt;:8890
</code></pre>
<p><strong>Save</strong> the config after making the adjustment.</p></li>
<li><p>Adjust two properties in the Hive config so that it references the Live Hive Proxy.</p>
<p><strong>Hive -&gt; Configs -&gt; Filter for <code>hive.metastore.uris</code></strong></p>
<p>Adjust the value of <code>hive.metastore.uris</code> in the following sub-sections:</p>
<p><em>General</em></p>
<pre><code class="hljs css language-json">thrift://&lt;docker_IP_address&gt;:9083
</code></pre>
<p><em>Advanced webhcat-site</em></p>
<pre><code class="hljs css language-json">hive.metastore.local=false,hive.metastore.uris=thrift://&lt;docker_IP_address&gt;:9083,hive.metastore.sasl.enabled=false
</code></pre>
<p><strong>Save</strong> the config after making these adjustments.</p></li>
<li><p><em>(TBC if this works or different approach required)</em></p>
<p>Add a property to the Hive config so that the Hive Metastore contacts the NameNode instead of the NameNode Proxy.</p>
<p><strong>Hive -&gt; Configs -&gt; Filter for <code>Custom hivemetastore-site</code></strong></p>
<p>Add the following property and value below to this sub-section:</p>
<p><em>Type = hivemetastore-site.xml</em></p>
<pre><code class="hljs css language-json">fs.defaultFS=hdfs://&lt;namenode_hostname_address&gt;:8020
</code></pre>
<p><strong>Save</strong> the config after making the addition.</p></li>
<li><p>Restart the <strong>HDFS</strong> and <strong>Hive</strong> services, as well as any others that are designated with a stale configuration.</p></li>
</ol>
<h3><a class="anchor" aria-hidden="true" id="setup-databricks-on-adls-gen2-zone"></a><a href="#setup-databricks-on-adls-gen2-zone" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Setup Databricks on ADLS Gen2 zone</h3>
<ol>
<li><p>Log into the Fusion UI for the ADLS Gen2 zone.</p>
<p><code>http://&lt;docker_hostname/IP&gt;:8583</code></p>
<p>Username: <code>admin</code>
Password: <code>admin</code></p></li>
<li><p>Enter the Databricks Configuration details on the Settings page.</p>
<p><strong>Fusion UI -&gt; Settings -&gt; Databricks: Configuration</strong></p>
<p><em>Examples for Databricks details</em></p>
<ul>
<li><p>Databricks Service Address: <code>westeurope.azuredatabricks.net</code></p></li>
<li><p>Bearer Token: <code>dapicd7689jkb25473c765ghty78bb299a83</code></p></li>
<li><p>Databricks Cluster ID: <code>2233-255452-boned277</code></p></li>
<li><p>Unique JDBC HTTP path: <code>sql/protocolv1/o/6987013384345789/2233-255452-boned277</code></p></li>
</ul>
<p>Click <strong>Update</strong> once complete.</p></li>
<li><p>Log into one of the containers for the ADLS Gen2 zone.</p>
<p>You will first need to obtain the name of a suitable container, this can be done by running the command below.</p>
<p><code>docker-compose ps</code> <em>- obtain list of container names.</em></p>
<p>Utilise a container name from the ADLS Gen2 zone in the command below, for example, <code>fusion-docker-compose_fusion-ui-server-adls2_1</code>.</p>
<p><code>docker exec -u root -it fusion-docker-compose_fusion-ui-server-adls2_1 bash</code></p></li>
<li><p>Upload the Live Analytics &quot;datatransformer&quot; jar using a curl command.</p>
<p><em>Example</em></p>
<p><code>curl -v -H &quot;Authorization: Bearer dapicd7689jkb25473c765ghty78bb299a83&quot; -F contents=@/opt/wandisco/fusion/plugins/databricks/live-analytics-databricks-etl-5.0.0.0-SNAPSHOT.jar -F path=&quot;/datatransformer.jar&quot; https://westeurope.azuredatabricks.net/api/2.0/dbfs/put</code></p>
<p>You will need to adjust the command so that your Bearer token and azuredatabricks URL is referenced.</p></li>
<li><p>Log into the Azure portal and Launch Workspace for your Databricks cluster.</p></li>
<li><p>On the left-hand panel, select <strong>Clusters</strong> and then select your interactive cluster.</p></li>
<li><p>Click on the <strong>Libraries</strong> tab, and select the option to <strong>Install New</strong>.</p></li>
<li><p>Select the following options for the Install Library prompt:</p>
<ul>
<li><p>Library Source = <code>DBFS</code></p></li>
<li><p>Library Type = <code>Jar</code></p></li>
<li><p>File Path = <code>dbfs:/datatransformer.jar</code></p></li>
</ul></li>
<li><p>Select <strong>Install</strong> once the details are entered. Wait for the <strong>Status</strong> of the jar to display as <strong>Installed</strong> before continuing.</p></li>
</ol>
<h3><a class="anchor" aria-hidden="true" id="replication-rules"></a><a href="#replication-rules" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Replication rules</h3>
<ol>
<li><p>Log into the Fusion UI for the HDP zone.</p>
<p><code>http://&lt;docker_hostname/IP&gt;:8083</code></p>
<p>Username: <code>admin</code>
Password: <code>wandisco</code></p></li>
<li><p>Enter the Replication tab, and select to <strong>+ Create</strong> a replication rule.</p></li>
<li><p>Create a new HCFS rule using the UI with the following properties:</p>
<ul>
<li><p>Type = <code>HCFS</code></p></li>
<li><p>Zones = <code>adls2, hdp</code> <em>- Leave as default.</em></p></li>
<li><p>Priority Zone = <code>hdp</code> <em>- Leave as default.</em></p></li>
<li><p>Rule Name = <code>warehouse</code></p></li>
<li><p>Path for adls2 = <code>/apps/hive/warehouse</code></p></li>
<li><p>Path for hdp = <code>/apps/hive/warehouse</code></p></li>
</ul>
<p>Click <strong>Add</strong> after entering the Rule Name and Paths.</p>
<ul>
<li>Advanced Options: Preserve Origin Block Size = <code>true</code> <em>- click the checkbox to set this to true.</em></li>
</ul>
<p>Click <strong>Create rules (1)</strong> once complete.</p></li>
<li><p>Create a new Hive rule using the UI with the following properties:</p>
<ul>
<li><p>Type = <code>Hive</code></p></li>
<li><p>Database name = <code>test*</code></p></li>
<li><p>Table name = <code>*</code></p></li>
<li><p>Description = <code>testing</code> <em>- this field is optional</em></p></li>
</ul>
<p>Click <strong>Create rule</strong> once complete.</p></li>
<li><p>Both rules should now display on the <strong>Replication</strong> tab in the Fusion UI.</p></li>
</ol>
<h2><a class="anchor" aria-hidden="true" id="testing-replication"></a><a href="#testing-replication" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Testing replication</h2>
<p>In this section, follow the steps detailed to perform live replication of HCFS data and Hive metadata from the HDP cluster to the Azure Databricks cluster.</p>
<p>Prior to performing these tasks, the Databricks cluster must be in a <strong>running</strong> state. Please access the Azure portal and check the status of the cluster. If it is not running, select to start the cluster and wait until it is <strong>running</strong> before continuing.</p>
<ol>
<li><p>Log into a HDP cluster node with the Hive client available.</p>
<p>You can confirm the Hive client is installed by switching to the <code>hdfs</code> user and running <code>hive</code> on the command line.</p>
<p><code>ssh &lt;hdp-cluster-node&gt;</code></p>
<p><code>su - hdfs</code></p>
<p><code>hive</code></p>
<p>After running the Hive command as the <code>hdfs</code> user, you will now be inside a Hive interactive session.</p></li>
<li><p>Create a database to use that will match the regex for the Hive replication rule created earlier in the Fusion UI.</p>
<p><code>hive&gt; create database test01;</code></p></li>
</ol>
<h2><a class="anchor" aria-hidden="true" id="advanced-options"></a><a href="#advanced-options" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Advanced options</h2>
<ul>
<li>This guide does not currently offer configuration of Fusion to a <strong>Kerberized</strong> HDP cluster.</li>
<li>This guide does not currently offer configuration of Fusion to a NameNode HA HDP cluster.</li>
</ul>
<p>Please contact <a href="https://wandisco.com/contact">WANdisco</a> for further information on Fusion with docker.</p>
</span></div></article></div><div class="docs-prevnext"></div></div></div><nav class="onPageNav"><ul class="toc-headings"><li><a href="#prerequisites">Prerequisites</a></li><li><a href="#guidance">Guidance</a><ul class="toc-headings"><li><a href="#initial-setup">Initial Setup</a></li><li><a href="#setup-prompts">Setup prompts</a></li><li><a href="#startup">Startup</a></li><li><a href="#live-hive-config-changes">Live Hive config changes</a></li><li><a href="#activate-namenode-proxy-and-live-hive-proxy-on-the-hdp-cluster">Activate NameNode Proxy and Live Hive Proxy on the HDP cluster</a></li><li><a href="#setup-databricks-on-adls-gen2-zone">Setup Databricks on ADLS Gen2 zone</a></li><li><a href="#replication-rules">Replication rules</a></li></ul></li><li><a href="#testing-replication">Testing replication</a></li><li><a href="#advanced-options">Advanced options</a></li></ul></nav></div><footer class="nav-footer" id="footer"><section class="sitemap"><a href="https://wandisco.github.io/wandisco-documentation/" class="nav-home"></a><div><h5>Docs</h5><a href="https://wandisco.github.io/wandisco-documentation/docs/en/quickstarts/quickstart-config.html">Getting Started</a><a href="https://docs.wandisco.com">Product User Guides</a><a href="https://community.wandisco.com/s/knowledge-base">Knowledge Base</a></div><div><h5>Community</h5><a href="https://community.wandisco.com/">WANdisco Community</a><a href="//wandisco.com/partners/find">Partners</a><a href="https://twitter.com/" target="_blank" rel="noreferrer noopener">Twitter</a></div><div><h5>More</h5><a href="https://wandisco.com/blog">Blog</a><a href="https://blogs.wandisco.com/">Developer Blog</a><a href="https://github.com/wandisco">GitHub</a></div></section><section class="copyright">Copyright © 2019 WANdisco, Inc.</section></footer></div><script type="text/javascript" src="https://cdn.jsdelivr.net/docsearch.js/1/docsearch.min.js"></script><script>
                document.addEventListener('keyup', function(e) {
                  if (e.target !== document.body) {
                    return;
                  }
                  // keyCode for '/' (slash)
                  if (e.keyCode === 191) {
                    const search = document.getElementById('search_input_react');
                    search && search.focus();
                  }
                });
              </script><script>
              var search = docsearch({
                
                apiKey: '56e573413aa88e9ec072a585bec45683',
                indexName: 'wandisco',
                inputSelector: '#search_input_react',
                algoliaOptions: {}
              });
            </script></body></html>