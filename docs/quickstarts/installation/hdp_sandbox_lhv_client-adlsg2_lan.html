<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><title>Hortonworks (HDP) Sandbox to Azure Databricks with LiveAnalytics · WANdisco docs</title><meta name="viewport" content="width=device-width"/><meta name="generator" content="Docusaurus"/><meta name="description" content="Use this quickstart if you want to configure Fusion to replicate from a non-kerberized Hortonworks (HDP) Sandbox to an Azure Databricks cluster."/><meta name="docsearch:language" content="en"/><meta property="og:title" content="Hortonworks (HDP) Sandbox to Azure Databricks with LiveAnalytics · WANdisco docs"/><meta property="og:type" content="website"/><meta property="og:url" content="https://wandisco.github.io/wandisco-documentation/ https://wandisco.github.io/wandisco-documentation/"/><meta property="og:description" content="Use this quickstart if you want to configure Fusion to replicate from a non-kerberized Hortonworks (HDP) Sandbox to an Azure Databricks cluster."/><meta property="og:image" content="https://wandisco.github.io/wandisco-documentation/ https://wandisco.github.io/wandisco-documentation/img/undraw_online.svg"/><meta name="twitter:card" content="summary"/><meta name="twitter:image" content="https://wandisco.github.io/wandisco-documentation/ https://wandisco.github.io/wandisco-documentation/img/undraw_tweetstorm.svg"/><link rel="shortcut icon" href="https://wandisco.github.io/wandisco-documentation/img/favicon.png"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/docsearch.js/1/docsearch.min.css"/><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css"/><script type="text/javascript" src="https://buttons.github.io/buttons.js"></script><script src="https://wandisco.github.io/wandisco-documentation/js/scrollSpy.js"></script><link rel="stylesheet" href="https://wandisco.github.io/wandisco-documentation/css/main.css"/><script src="https://wandisco.github.io/wandisco-documentation/js/codetabs.js"></script></head><body class="sideNavVisible separateOnPageNav"><div class="fixedHeaderContainer"><div class="headerWrapper wrapper"><header><a href="https://wandisco.github.io/wandisco-documentation/"><img class="logo" src="https://wandisco.github.io/wandisco-documentation/img/favicon.png" alt="WANdisco docs"/><h2 class="headerTitleWithLogo">WANdisco docs</h2></a><div class="navigationWrapper navigationSlider"><nav class="slidingNav"><ul class="nav-site nav-site-internal"><li class=""><a href="https://wandisco.github.io/wandisco-documentation/docs/why-fusion/benefits" target="_self">Why Fusion?</a></li><li class="siteNavGroupActive"><a href="https://wandisco.github.io/wandisco-documentation/docs/quickstarts/installation/quickstart-config" target="_self">Quickstarts</a></li><li class=""><a href="https://wandisco.github.io/wandisco-documentation/docs/docs/doc1" target="_self">Docs</a></li><li class=""><a href="https://wandisco.github.io/wandisco-documentation/docs/glossary/a" target="_self">Glossary</a></li><li class=""><a href="https://wandisco.github.io/wandisco-documentation/docs/help/need_help" target="_self">Help</a></li><li class="navSearchWrapper reactNavSearchWrapper"><input type="text" id="search_input_react" placeholder="Search" title="Search"/></li></ul></nav></div></header></div></div><div class="navPusher"><div class="docMainWrapper wrapper"><div class="docsNavContainer" id="docsNav"><nav class="toc"><div class="toggleNav"><section class="navWrapper wrapper"><div class="navBreadcrumb wrapper"><div class="navToggle" id="navToggler"><div class="hamburger-menu"><div class="line1"></div><div class="line2"></div><div class="line3"></div></div></div><h2><i>›</i><span>Installation</span></h2><div class="tocToggler" id="tocToggler"><i class="icon-toc"></i></div></div><div class="navGroups"><div class="navGroup"><h3 class="navGroupCategoryTitle collapsible">Preparation<span class="arrow"><svg width="24" height="24" viewBox="0 0 24 24"><path fill="#565656" d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path d="M0 0h24v24H0z" fill="none"></path></svg></span></h3><ul class="hide"><li class="navListItem"><a class="navItem" href="https://wandisco.github.io/wandisco-documentation/docs/quickstarts/preparation/azure_vm_creation">Azure VM creation</a></li><li class="navListItem"><a class="navItem" href="https://wandisco.github.io/wandisco-documentation/docs/quickstarts/preparation/azure_vm_prep">Azure VM preparation</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle collapsible">Installation<span class="arrow"><svg width="24" height="24" viewBox="0 0 24 24"><path fill="#565656" d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path d="M0 0h24v24H0z" fill="none"></path></svg></span></h3><ul class="hide"><li class="navListItem"><a class="navItem" href="https://wandisco.github.io/wandisco-documentation/docs/quickstarts/installation/quickstart-config">Introduction</a></li><li class="navListItem"><a class="navItem" href="https://wandisco.github.io/wandisco-documentation/docs/quickstarts/installation/adlsg1-adlsg2">ADLS Gen1 to ADLS Gen2</a></li><li class="navListItem"><a class="navItem" href="https://wandisco.github.io/wandisco-documentation/docs/quickstarts/installation/hdp-adlsg2">Hortonworks (HDP) to ADLS Gen2</a></li><li class="navListItem"><a class="navItem" href="https://wandisco.github.io/wandisco-documentation/docs/quickstarts/installation/cdh-adlsg2">Cloudera (CDH) to ADLS Gen2</a></li><li class="navListItem navListItemActive"><a class="navItem" href="https://wandisco.github.io/wandisco-documentation/docs/quickstarts/installation/hdp_sandbox_lhv_client-adlsg2_lan">HDP Sandbox to Azure Databricks with LiveAnalytics</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle collapsible">Operation<span class="arrow"><svg width="24" height="24" viewBox="0 0 24 24"><path fill="#565656" d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path d="M0 0h24v24H0z" fill="none"></path></svg></span></h3><ul class="hide"><li class="navListItem"><a class="navItem" href="https://wandisco.github.io/wandisco-documentation/docs/quickstarts/operation/create-rule">Create a Rule</a></li><li class="navListItem"><a class="navItem" href="https://wandisco.github.io/wandisco-documentation/docs/quickstarts/operation/migration">Start a Migration</a></li><li class="navListItem"><a class="navItem" href="https://wandisco.github.io/wandisco-documentation/docs/quickstarts/operation/hdp_sandbox_fusion_stop_start">Stop/Start HDP Sandbox &amp; WANdisco Fusion</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle collapsible">Troubleshooting<span class="arrow"><svg width="24" height="24" viewBox="0 0 24 24"><path fill="#565656" d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path d="M0 0h24v24H0z" fill="none"></path></svg></span></h3><ul class="hide"><li class="navListItem"><a class="navItem" href="https://wandisco.github.io/wandisco-documentation/docs/quickstarts/troubleshooting/useful_info">Useful information</a></li><li class="navListItem"><a class="navItem" href="https://wandisco.github.io/wandisco-documentation/docs/quickstarts/troubleshooting/hdp_sandbox_lan_troubleshooting">HDP Sandbox to Azure Databricks</a></li><li class="navListItem"><a class="navItem" href="https://wandisco.github.io/wandisco-documentation/docs/quickstarts/troubleshooting/logs">Logs</a></li></ul></div></div></section></div><script>
            var coll = document.getElementsByClassName('collapsible');
            var checkActiveCategory = true;
            for (var i = 0; i < coll.length; i++) {
              var links = coll[i].nextElementSibling.getElementsByTagName('*');
              if (checkActiveCategory){
                for (var j = 0; j < links.length; j++) {
                  if (links[j].classList.contains('navListItemActive')){
                    coll[i].nextElementSibling.classList.toggle('hide');
                    coll[i].childNodes[1].classList.toggle('rotate');
                    checkActiveCategory = false;
                    break;
                  }
                }
              }

              coll[i].addEventListener('click', function() {
                var arrow = this.childNodes[1];
                arrow.classList.toggle('rotate');
                var content = this.nextElementSibling;
                content.classList.toggle('hide');
              });
            }

            document.addEventListener('DOMContentLoaded', function() {
              createToggler('#navToggler', '#docsNav', 'docsSliderActive');
              createToggler('#tocToggler', 'body', 'tocActive');

              var headings = document.querySelector('.toc-headings');
              headings && headings.addEventListener('click', function(event) {
                var el = event.target;
                while(el !== headings){
                  if (el.tagName === 'A') {
                    document.body.classList.remove('tocActive');
                    break;
                  } else{
                    el = el.parentNode;
                  }
                }
              }, false);

              function createToggler(togglerSelector, targetSelector, className) {
                var toggler = document.querySelector(togglerSelector);
                var target = document.querySelector(targetSelector);

                if (!toggler) {
                  return;
                }

                toggler.onclick = function(event) {
                  event.preventDefault();

                  target.classList.toggle(className);
                };
              }
            });
        </script></nav></div><div class="container mainContainer"><div class="wrapper"><div class="post"><header class="postHeader"><h1 class="postHeaderTitle">Hortonworks (HDP) Sandbox to Azure Databricks with LiveAnalytics</h1></header><article><div><span><p>Use this quickstart if you want to configure Fusion to replicate from a non-kerberized Hortonworks (HDP) Sandbox to an Azure Databricks cluster.</p>
<p>This will involve the use of Live Hive for the HDP cluster, and the Fusion Plugin for Databricks Delta Lake for the Azure Databricks cluster. These two products form the LiveAnalytics solution.</p>
<p>What this guide will cover:</p>
<ul>
<li>Installing WANdisco Fusion using the <a href="https://docs.docker.com/compose/">docker-compose</a> tool.</li>
<li>Integrating WANdisco Fusion with Azure Databricks.</li>
<li>Performing a sample data migration.</li>
</ul>
<p>Please see the <a href="https://wandisco.github.io/wandisco-documentation/docs/quickstarts/operation/hdp_sandbox_fusion_stop_start">shutdown and start up</a> guide for when you wish to safely shutdown or start back up the environment.</p>
<h2><a class="anchor" aria-hidden="true" id="prerequisites"></a><a href="#prerequisites" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Prerequisites</h2>
<p>To complete this quickstart, you will need:</p>
<ul>
<li><p>ADLS Gen2 storage account with <a href="https://docs.microsoft.com/en-us/azure/storage/blobs/data-lake-storage-namespace">hierarchical namespace</a> enabled. You will also need:</p>
<ul>
<li>A container created inside this account.</li>
<li>Your <a href="https://docs.microsoft.com/en-us/azure/storage/common/storage-account-keys-manage#view-access-keys-and-connection-string">Access Key</a> for the account.</li>
</ul></li>
<li><p>Azure Databricks cluster with the following credential information:</p>
<ul>
<li><p><a href="https://docs.databricks.com/workspace/workspace-details.html#workspace-instance-and-id">Databricks Service Address (Instance name)</a> (Example: <code>westeurope.azuredatabricks.net</code>)</p></li>
<li><p><a href="https://docs.databricks.com/dev-tools/api/latest/authentication.html#generate-a-token">Bearer Token</a> (Example: <code>dapibe21cfg45efae945t6f0b57dfd1dffb4</code>)</p></li>
<li><p><a href="https://docs.databricks.com/workspace/workspace-details.html#cluster-url">Databricks Cluster ID</a> (Example: <code>0234-125567-cowls978</code>)</p></li>
<li><p><a href="https://docs.databricks.com/bi/jdbc-odbc-bi.html#construct-the-jdbc-url">Unique JDBC HTTP path</a> (Example: <code>sql/protocolv1/o/8445611090456789/0234-125567-cowls978</code>)</p></li>
</ul></li>
<li><p>Azure VM created and started, matching the following specifications:</p>
<ul>
<li>Minimum size VM recommendation = <strong>Standard D4 v3 (4 vcpus, 16 GiB memory).</strong></li>
<li>A minimum of 24GB available storage for the <code>/var/lib/docker</code> directory.</li>
</ul>
<p>If seeking guidance on how to create a suitable VM with all utilities installed, see our <a href="https://wandisco.github.io/wandisco-documentation/docs/quickstarts/preparation/azure_vm_creation">Azure VM creation</a> guide.</p></li>
<li><p>The following utilities must be installed on the server:</p>
<ul>
<li><a href="https://git-scm.com/book/en/v2/Getting-Started-Installing-Git">Git</a></li>
<li><a href="https://docs.docker.com/install/">Docker</a> (v19.03.5 or higher)</li>
<li><a href="https://docs.docker.com/compose/install/#install-compose">Docker Compose for Linux</a> (v1.25.0 or higher)</li>
</ul>
<p>If seeking guidance on how to install these utilities, see our <a href="https://wandisco.github.io/wandisco-documentation/docs/quickstarts/preparation/azure_vm_prep">Azure VM preparation</a> guide. This is not required if you have used our <a href="https://wandisco.github.io/wandisco-documentation/docs/quickstarts/preparation/azure_vm_creation">Azure VM creation</a> guide as all utilities will have been included.</p></li>
</ul>
<p><em>These instructions have been tested on Ubuntu LTS.</em></p>
<h2><a class="anchor" aria-hidden="true" id="installation"></a><a href="#installation" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Installation</h2>
<p>Please log in to your VM prior to starting these steps.</p>
<h3><a class="anchor" aria-hidden="true" id="setup-fusion"></a><a href="#setup-fusion" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Setup Fusion</h3>
<ol>
<li><p>Clone the Fusion docker repository to your Azure VM instance:</p>
<p><code>git clone https://github.com/WANdisco/fusion-docker-compose.git</code></p></li>
<li><p>Change to the repository directory:</p>
<p><code>cd fusion-docker-compose</code></p></li>
<li><p>Run the setup script:</p>
<p><code>./setup-env.sh</code></p></li>
<li><p>Enter <code>y</code> when asked whether to use the HDP sandbox.</p></li>
<li><p>Follow the prompts to configure your ADLS Gen2 Zone, see the next section below for guidance on this.</p></li>
</ol>
<h4><a class="anchor" aria-hidden="true" id="setup-prompts-for-adls-gen2"></a><a href="#setup-prompts-for-adls-gen2" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Setup prompts for ADLS Gen2</h4>
<p>Please ensure to enter your details for the <strong>Storage account</strong>, <strong>Storage container</strong> and <strong>Account Key</strong> values so that they match your account in Azure.
The examples shown below are for guidance only.</p>
<ul>
<li><p>Storage account: <code>adlsg2storage</code></p></li>
<li><p>Storage container: <code>fusionreplication</code></p></li>
<li><p>Account key: <code>KEY_1_STRING</code> - the Primary Access Key is now referred to as &quot;Key1&quot; in Microsoft’s documentation. You can get the Access Key from the Microsoft Azure storage account under the <strong>Access Keys</strong> section.</p></li>
<li><p>default FS: <code>abfss://fusionreplication@adlsg2storage.dfs.core.windows.net/</code> - press enter for the default value.</p></li>
<li><p>underlying FS: <code>abfs://fusionreplication@adlsg2storage.dfs.core.windows.net/</code> - press enter for the default value.</p></li>
</ul>
<p>At this point, the setup prompts will be complete and the script will exit out with an informational message.</p>
<h3><a class="anchor" aria-hidden="true" id="startup-fusion"></a><a href="#startup-fusion" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Startup Fusion</h3>
<p>After all the prompts have been completed, you will be able to start the containers:</p>
<p><code>docker-compose up -d</code></p>
<p>Docker will now download all required images and create the containers, please wait until this is done.</p>
<h2><a class="anchor" aria-hidden="true" id="configuration"></a><a href="#configuration" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Configuration</h2>
<h3><a class="anchor" aria-hidden="true" id="install-liveanalytics-on-databricks-cluster"></a><a href="#install-liveanalytics-on-databricks-cluster" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Install LiveAnalytics on Databricks cluster</h3>
<p>Prior to performing these tasks, the Databricks cluster must be in a <strong>running</strong> state. Please access the Azure portal and check the status of the cluster. If it is not running, select to start the cluster and wait until it is <strong>running</strong>.</p>
<ol>
<li><p>On the docker host, log in to a container for the ADLS Gen2 zone.</p>
<p><code>docker-compose exec fusion-server-adls2 bash</code></p></li>
</ol>
<ol start="2">
<li><p>Upload the LiveAnalytics 'datatransformer.jar' using a curl command.</p>
<p><code>curl -v -H &quot;Authorization: Bearer &lt;bearer_token&gt;&quot; -F contents=@/opt/wandisco/fusion/plugins/live-deltalake/live-analytics-databricks-etl-6.0.0.1.jar -F path=&quot;/datatransformer.jar&quot; https://&lt;databricks_service_address&gt;/api/2.0/dbfs/put</code></p>
<p>You will need to adjust the <code>curl</code> command so that your <a href="https://docs.databricks.com/dev-tools/api/latest/authentication.html#generate-a-token">&lt;bearer_token&gt;</a> and <a href="https://docs.databricks.com/dev-tools/databricks-connect.html#step-2-configure-connection-properties">&lt;databricks_service_address&gt;</a> is referenced.</p>
<p><em>Example values</em></p>
<ul>
<li>Bearer Token: <code>dapibe21cfg45efae945t6f0b57dfd1dffb4</code></li>
<li>Databricks Service Address: <code>westeurope.azuredatabricks.net</code></li>
</ul>
<p><em>Example command</em></p>
<p><code>curl -v -H &quot;Authorization: Bearer dapibe21cfg45efae945t6f0b57dfd1dffb4&quot; -F contents=@/opt/wandisco/fusion/plugins/live-deltalake/live-analytics-databricks-etl-6.0.0.1.jar -F path=&quot;/datatransformer.jar&quot; https://westeurope.azuredatabricks.net/api/2.0/dbfs/put</code></p>
<p>If the command is successful, you will see that the message output contains the following text below:</p>
<pre><code class="hljs css language-json">&lt; HTTP/1.1 100 Continue
&lt; HTTP/1.1 200 OK
</code></pre></li>
<li><p>Exit back into the docker host once complete.</p>
<p><code>exit</code></p></li>
<li><p>In your Workspace for the Databricks cluster, on the left-hand panel, select <strong>Clusters</strong> and then select your interactive cluster.</p></li>
<li><p>Click on the <strong>Libraries</strong> tab, and select the option to <strong>Install New</strong>.</p></li>
<li><p>Select the following options for the Install Library prompt:</p>
<ul>
<li><p>Library Source = <code>DBFS</code></p></li>
<li><p>Library Type = <code>Jar</code></p></li>
<li><p>File Path = <code>dbfs:/datatransformer.jar</code></p></li>
</ul></li>
<li><p>Select <strong>Install</strong> once the details are entered.</p>
<p>Wait for the <strong>Status</strong> of the jar to display as <strong>Installed</strong> before continuing.</p></li>
</ol>
<h3><a class="anchor" aria-hidden="true" id="check-hdp-services-are-started"></a><a href="#check-hdp-services-are-started" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Check HDP services are started</h3>
<p>The HDP sandbox services can take up to 5-10 minutes to start. You will need to ensure that the HDFS service is started before continuing.</p>
<ol>
<li><p>Log in to the Ambari UI via a web browser.</p>
<p><code>http://&lt;docker_IP_address&gt;:8080</code></p>
<p>Username: <code>admin</code>
Password: <code>admin</code></p></li>
<li><p>Select the <strong>HDFS</strong> service.</p></li>
<li><p>Wait until all the HDFS components are showing as <strong>Started</strong>.</p></li>
</ol>
<h3><a class="anchor" aria-hidden="true" id="live-hive-activation"></a><a href="#live-hive-activation" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Live Hive activation</h3>
<ol>
<li><p>Log into the Fusion UI for the HDP zone, and activate the Live Hive plugin.</p>
<p><code>http://&lt;docker_IP_address&gt;:8083</code></p>
<p>Username: <code>admin</code>
Password: <code>admin</code></p></li>
<li><p>Proceed to the Settings tab and select the <em>Live Hive: Plugin Activation</em> option on the left-hand panel.</p></li>
<li><p>Click on the <em>Activate</em> option. Wait for the <strong>Reload this window</strong> message to appear and refresh the page.</p></li>
</ol>
<h3><a class="anchor" aria-hidden="true" id="setup-databricks-in-fusion"></a><a href="#setup-databricks-in-fusion" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Setup Databricks in Fusion</h3>
<ol>
<li><p>Log in to the Fusion UI for the ADLS Gen2 zone.</p>
<p><code>http://&lt;docker_IP_address&gt;:8583</code></p>
<p>Username: <code>admin</code>
Password: <code>admin</code></p></li>
<li><p>Enter your Databricks Configuration details on the Settings page.</p>
<p><strong>Fusion UI -&gt; Settings -&gt; Databricks: Configuration</strong></p>
<ul>
<li><p><a href="https://docs.databricks.com/workspace/workspace-details.html#workspace-instance-and-id">Databricks Service Address (Instance name)</a> (Example: <code>westeurope.azuredatabricks.net</code>)</p></li>
<li><p><a href="https://docs.databricks.com/dev-tools/api/latest/authentication.html#generate-a-token">Bearer Token</a> (Example: <code>dapibe21cfg45efae945t6f0b57dfd1dffb4</code>)</p></li>
<li><p><a href="https://docs.databricks.com/workspace/workspace-details.html#cluster-url">Databricks Cluster ID</a> (Example: <code>0234-125567-cowls978</code>)</p></li>
<li><p><a href="https://docs.databricks.com/bi/jdbc-odbc-bi.html#construct-the-jdbc-url">Unique JDBC HTTP path</a> (Example: <code>sql/protocolv1/o/8445611090456789/0234-125567-cowls978</code>)</p></li>
</ul>
<p>Click <strong>Update</strong> once complete.</p></li>
</ol>
<h2><a class="anchor" aria-hidden="true" id="replication"></a><a href="#replication" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Replication</h2>
<p>Follow the steps detailed to perform live replication of HCFS data and Hive metadata from the HDP sandbox to the Azure Databricks cluster.</p>
<h3><a class="anchor" aria-hidden="true" id="create-replication-rules"></a><a href="#create-replication-rules" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Create replication rules</h3>
<ol>
<li><p>Log in to the Fusion UI for the HDP zone.</p>
<p><code>http://&lt;docker_IP_address:8083</code></p>
<p>Username: <code>admin</code>
Password: <code>admin</code></p></li>
<li><p>Enter the Replication tab, and select to <strong>+ Create</strong> a replication rule.</p></li>
</ol>
<ol start="3">
<li><p>Create a new HCFS rule using the UI with the following properties:</p>
<ul>
<li><p>Type = <code>HCFS</code></p></li>
<li><p>Zones = <code>adls2, sandbox-hdp</code> <em>- Leave as default.</em></p></li>
<li><p>Priority Zone = <code>sandbox-hdp</code> <em>- Leave as default.</em></p></li>
<li><p>Rule Name = <code>warehouse</code></p></li>
<li><p>Path for adls2 = <code>/apps/hive/warehouse</code></p></li>
<li><p>Path for hdp = <code>/apps/hive/warehouse</code></p></li>
</ul>
<p>Click <strong>Add</strong> after entering the Rule Name and Paths.</p>
<ul>
<li><p><strong>IMPORTANT - Advanced Options:</strong></p>
<ul>
<li>Preserve Origin Block Size = <code>true</code> <em>- Click the checkbox to set this to true.</em></li>
</ul></li>
</ul>
<p>Click <strong>Create rules (1)</strong> once complete.</p></li>
<li><p>Create a new Hive rule using the UI with the following properties:</p>
<p>On the Replication tab, select to <strong>+ Create</strong> a replication rule again.</p>
<ul>
<li><p>Type = <code>Hive</code></p></li>
<li><p>Database name = <code>databricks_demo</code></p></li>
<li><p>Table name = <code>*</code></p></li>
<li><p>Description = <code>Demo</code> <em>- this field is optional</em></p></li>
</ul>
<p>Click <strong>Create rule</strong> once complete.</p></li>
<li><p>Both rules should now display on the <strong>Replication</strong> tab in the Fusion UI.</p></li>
</ol>
<h3><a class="anchor" aria-hidden="true" id="test-replication"></a><a href="#test-replication" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Test replication</h3>
<p>Prior to performing these tasks, the Databricks cluster must be in a <strong>running</strong> state. Please access the Azure portal and check the status of the cluster. If it is not running, select to start the cluster and wait until it is <strong>running</strong>.</p>
<ol>
<li><p>Return to the terminal session on the <strong>Docker host</strong>.</p></li>
<li><p>Log in to the <strong>sandbox-hdp</strong> container as the hdfs user and place data into HDFS.</p>
<p>a. Log in to the container.</p>
<p><code>docker-compose exec -u hdfs sandbox-hdp bash</code></p>
<p>b. Change directory to <em>tmp</em>.</p>
<p><code>cd /tmp/</code></p>
<p>c. Obtain the sample data to be used with the Hive table.</p>
<p><code>curl -o customer_addresses_dim.tsv.gz -Lf 'https://github.com/pivotalsoftware/pivotal-samples/blob/master/sample-data/customer_addresses_dim.tsv.gz?raw=true'</code></p>
<p>d. Create a directory within HDFS for the sample data.</p>
<p><code>hdfs dfs -mkdir -p /retail_demo/customer_addresses_dim_hive/</code></p>
<p>e. Place the sample data into HDFS, so that it can be accessed by Hive.</p>
<p><code>hdfs dfs -put customer_addresses_dim.tsv.gz /retail_demo/customer_addresses_dim_hive/</code></p></li>
<li><p>Use beeline to start a Hive session and connect to the Hiveserver2 service as hdfs user.</p>
<p><code>beeline -u jdbc:hive2://sandbox-hdp:10000/ -n hdfs</code></p>
<p>An alternative connection string can also be found on the Ambari UI under <strong>Hive -&gt; Summary -&gt; HIVESERVER2 JDBC URL</strong>.</p></li>
<li><p>Create a database to use that will store the sample data.</p>
<p><code>CREATE DATABASE IF NOT EXISTS retail_demo;</code></p></li>
<li><p>Create a table inside of the database that points to the data previously uploaded.</p>
<pre><code class="hljs css language-sql"><span class="hljs-keyword">CREATE</span> <span class="hljs-keyword">TABLE</span> retail_demo.customer_addresses_dim_hive
(
Customer_Address_ID  <span class="hljs-built_in">bigint</span>,
Customer_ID          <span class="hljs-built_in">bigint</span>,
Valid_From_Timestamp <span class="hljs-built_in">timestamp</span>,
Valid_To_Timestamp   <span class="hljs-built_in">timestamp</span>,
House_Number         <span class="hljs-keyword">string</span>,
Street_Name          <span class="hljs-keyword">string</span>,
Appt_Suite_No        <span class="hljs-keyword">string</span>,
City                 <span class="hljs-keyword">string</span>,
State_Code           <span class="hljs-keyword">string</span>,
Zip_Code             <span class="hljs-keyword">string</span>,
Zip_Plus_Four        <span class="hljs-keyword">string</span>,
Country              <span class="hljs-keyword">string</span>,
Phone_Number         <span class="hljs-keyword">string</span>
)
<span class="hljs-keyword">ROW</span> <span class="hljs-keyword">FORMAT</span> <span class="hljs-keyword">DELIMITED</span> <span class="hljs-keyword">FIELDS</span> <span class="hljs-keyword">TERMINATED</span> <span class="hljs-keyword">BY</span> <span class="hljs-string">'\t'</span>
<span class="hljs-keyword">STORED</span> <span class="hljs-keyword">AS</span> TEXTFILE
LOCATION <span class="hljs-string">'/retail_demo/customer_addresses_dim_hive/'</span>;
</code></pre></li>
<li><p>Create a second database that will match the regex for the Hive replication rule created earlier in the Fusion UI.</p>
<p><code>CREATE DATABASE IF NOT EXISTS databricks_demo;</code></p></li>
<li><p>Create a table inside this second database:</p>
<pre><code class="hljs css language-sql"><span class="hljs-keyword">CREATE</span> <span class="hljs-keyword">TABLE</span> databricks_demo.customer_addresses_dim_hive
(
Customer_Address_ID  <span class="hljs-built_in">bigint</span>,
Customer_ID          <span class="hljs-built_in">bigint</span>,
Valid_From_Timestamp <span class="hljs-built_in">timestamp</span>,
Valid_To_Timestamp   <span class="hljs-built_in">timestamp</span>,
House_Number         <span class="hljs-keyword">string</span>,
Street_Name          <span class="hljs-keyword">string</span>,
Appt_Suite_No        <span class="hljs-keyword">string</span>,
City                 <span class="hljs-keyword">string</span>,
State_Code           <span class="hljs-keyword">string</span>,
Zip_Code             <span class="hljs-keyword">string</span>,
Zip_Plus_Four        <span class="hljs-keyword">string</span>,
Country              <span class="hljs-keyword">string</span>,
Phone_Number         <span class="hljs-keyword">string</span>
)
<span class="hljs-keyword">stored</span> <span class="hljs-keyword">as</span> ORC;
</code></pre></li>
</ol>
<ol start="8">
<li><p>Now insert data into the table by running the following:</p>
<p><code>insert into databricks_demo.customer_addresses_dim_hive select * from retail_demo.customer_addresses_dim_hive where state_code ='CA';</code></p>
<p>This will now launch a Hive job that will insert the data values provided in this example. If this is successful, you will see <strong>SUCCEEDED</strong> written in the STATUS column.</p>
<pre><code class="hljs css language-json">--------------------------------------------------------------------------------
        VERTICES      STATUS  TOTAL  COMPLETED  RUNNING  PENDING  FAILED  KILLED
--------------------------------------------------------------------------------
Map 1 ..........   SUCCEEDED      1          1        0        0       0       0
--------------------------------------------------------------------------------
VERTICES: 01/01  [==========================&gt;&gt;] 100%  ELAPSED TIME: X.YZ s
--------------------------------------------------------------------------------
</code></pre>
<p>The data will take a few moments to be replicated and appear in the Databricks cluster.</p></li>
</ol>
<h3><a class="anchor" aria-hidden="true" id="setup-databricks-notebook-to-view-data"></a><a href="#setup-databricks-notebook-to-view-data" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Setup Databricks Notebook to view data</h3>
<ol>
<li><p>Return to your Workspace for the Databricks cluster.</p></li>
<li><p>Create a Cluster Notebook.</p>
<p><strong>Click Workspace on the left hand side &gt; click the drop down arrow &gt; Create &gt; Notebook</strong></p>
<ul>
<li>Name: <strong>WD-demo</strong></li>
<li>Language: <strong>SQL</strong></li>
<li>Cluster: (Choose the cluster used in this demo)</li>
</ul>
<p>Click <strong>Create</strong>.</p></li>
<li><p>You should now see a blank notebook.</p>
<p>a. Inside the 'Cmd 1' box, add the query:</p>
<p><code>select * from databricks_demo.customer_addresses_dim_hive;</code></p>
<p>b. Click 'Run Cell' (looks like a play button in the top right of that box).</p></li>
<li><p>Wait for the query to return, then select the drop-down graph type and choose <strong>Map</strong>.</p></li>
<li><p>Under the Plot Options &gt; remove all Keys &gt; click and drag 'state_code' from the 'All fields' box into the 'Keys' box.</p></li>
<li><p>Click Apply.</p></li>
<li><p>You should now see a plot of USA with colour shading - dependent on the population density.</p></li>
<li><p>If desired, you can repeat this process except using the Texas state code instead of California.</p>
<p>a. Back in the Hive beeline session on the <strong>fusion_sandbox-hdp_1</strong> container, run the following command:</p>
<p><code>insert into databricks_demo.customer_addresses_dim_hive select * from retail_demo.customer_addresses_dim_hive where state_code ='TX';</code></p>
<p>b. Repeat from step 3 to observe the results for Texas.</p></li>
</ol>
<p>You have now completed this demo.</p>
<h2><a class="anchor" aria-hidden="true" id="troubleshooting"></a><a href="#troubleshooting" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Troubleshooting</h2>
<ul>
<li><p>Please see our <a href="https://wandisco.github.io/wandisco-documentation/docs/quickstarts/troubleshooting/hdp_sandbox_lan_troubleshooting">Troubleshooting</a> guide for help with this demo.</p></li>
<li><p>Please contact <a href="https://wandisco.com/contact">WANdisco</a> for further information about Fusion.</p></li>
</ul>
</span></div></article></div><div class="docs-prevnext"><a class="docs-prev button" href="https://wandisco.github.io/wandisco-documentation/docs/quickstarts/installation/cdh-adlsg2"><span class="arrow-prev">← </span><span>Cloudera (CDH) to ADLS Gen2</span></a><a class="docs-next button" href="https://wandisco.github.io/wandisco-documentation/docs/quickstarts/operation/create-rule"><span>Create a Rule</span><span class="arrow-next"> →</span></a></div></div></div><nav class="onPageNav"><ul class="toc-headings"><li><a href="#prerequisites">Prerequisites</a></li><li><a href="#installation">Installation</a><ul class="toc-headings"><li><a href="#setup-fusion">Setup Fusion</a></li><li><a href="#startup-fusion">Startup Fusion</a></li></ul></li><li><a href="#configuration">Configuration</a><ul class="toc-headings"><li><a href="#install-liveanalytics-on-databricks-cluster">Install LiveAnalytics on Databricks cluster</a></li><li><a href="#check-hdp-services-are-started">Check HDP services are started</a></li><li><a href="#live-hive-activation">Live Hive activation</a></li><li><a href="#setup-databricks-in-fusion">Setup Databricks in Fusion</a></li></ul></li><li><a href="#replication">Replication</a><ul class="toc-headings"><li><a href="#create-replication-rules">Create replication rules</a></li><li><a href="#test-replication">Test replication</a></li><li><a href="#setup-databricks-notebook-to-view-data">Setup Databricks Notebook to view data</a></li></ul></li><li><a href="#troubleshooting">Troubleshooting</a></li></ul></nav></div><footer class="nav-footer" id="footer"><section class="sitemap"><a href="https://wandisco.github.io/wandisco-documentation/" class="nav-home"></a><div><h5>Docs</h5><a href="https://wandisco.github.io/wandisco-documentation/docs/en/quickstarts/quickstart-config.html">Getting Started</a><a href="https://docs.wandisco.com">Product User Guides</a><a href="https://community.wandisco.com/s/knowledge-base">Knowledge Base</a></div><div><h5>Community</h5><a href="https://community.wandisco.com/">WANdisco Community</a><a href="//wandisco.com/partners/find">Partners</a><a href="https://twitter.com/" target="_blank" rel="noreferrer noopener">Twitter</a></div><div><h5>More</h5><a href="https://wandisco.com/blog">Blog</a><a href="https://blogs.wandisco.com/">Developer Blog</a><a href="https://github.com/wandisco">GitHub</a></div></section><section class="copyright">Copyright © 2020 WANdisco, Inc.</section></footer></div><script type="text/javascript" src="https://cdn.jsdelivr.net/docsearch.js/1/docsearch.min.js"></script><script>
                document.addEventListener('keyup', function(e) {
                  if (e.target !== document.body) {
                    return;
                  }
                  // keyCode for '/' (slash)
                  if (e.keyCode === 191) {
                    const search = document.getElementById('search_input_react');
                    search && search.focus();
                  }
                });
              </script><script>
              var search = docsearch({
                
                apiKey: '56e573413aa88e9ec072a585bec45683',
                indexName: 'wandisco',
                inputSelector: '#search_input_react',
                algoliaOptions: {}
              });
            </script></body></html>